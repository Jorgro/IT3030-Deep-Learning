{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_z = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 13, 13, 32)        320       \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 2304)              0         \n",
      "                                                                 \n",
      " z_params (Dense)            (None, 16)                36880     \n",
      "                                                                 \n",
      " z_layer (IndependentNormal)  ((None, 8),              0         \n",
      "                              (None, 8))                         \n",
      "                                                                 \n",
      " input_26 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1568)              14112     \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_21 (Conv2D  (None, 14, 14, 64)       18496     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_22 (Conv2D  (None, 28, 28, 32)       18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_23 (Conv2D  (None, 28, 28, 1)        289       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " x_params (Flatten)          (None, 784)               0         \n",
      "                                                                 \n",
      " x_layer (IndependentBernoul  ((None, 28, 28, 1),      0         \n",
      " li)                          (None, 28, 28, 1))                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,057\n",
      "Trainable params: 107,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prior = tfp.distributions.Independent(\n",
    "            tfp.distributions.Normal(loc=tf.zeros(dim_z), scale=1.0),\n",
    "            reinterpreted_batch_ndims=1,\n",
    "        )\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            ) (input_img)\n",
    "x = layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            ) (x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(\n",
    "                tfp.layers.IndependentNormal.params_size(dim_z),\n",
    "                activation=None,\n",
    "                name=\"z_params\",\n",
    "            )(x)\n",
    "encoded = tfp.layers.IndependentNormal(\n",
    "                dim_z,\n",
    "                activity_regularizer=tfp.layers.KLDivergenceRegularizer(\n",
    "                    prior, weight=3.0\n",
    "                ),\n",
    "                name=\"z_layer\",)(x)\n",
    "\n",
    "decoder_input = layers.InputLayer(input_shape=dim_z)(encoded)\n",
    "x = layers.Dense(7 * 7 * 32, activation=None)(decoder_input)\n",
    "x = layers.Reshape((7, 7, 32))(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "x = layers.Flatten(name=\"x_params\")(x)\n",
    "decoded = tfp.layers.IndependentBernoulli((28, 28, 1), name=\"x_layer\")(x)\n",
    "vae = keras.Model(input_img, decoded)\n",
    "vae.compile(optimizer='adam', loss=lambda x, y: -y.log_prob(x))\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_4163/4188248072.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_4163/4188248072.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)\n"
     ]
    }
   ],
   "source": [
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "import numpy as np\n",
    "\n",
    "generator = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=2048)\n",
    "\n",
    "x_train, y_train = generator.get_full_data_set(training=True)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
    "x_test = x_test[:, :, :, [0]]\n",
    "y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 30s 62ms/step - loss: 145.7182 - val_loss: 82.2264\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 70.6711 - val_loss: 62.2635\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 59.1235 - val_loss: 55.4826\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 54.7906 - val_loss: 52.8308\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 52.2361 - val_loss: 51.1366\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 50.5484 - val_loss: 49.4672\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 49.1951 - val_loss: 48.6446\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 48.2101 - val_loss: 47.8222\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 47.0500 - val_loss: 46.3093\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 45.5512 - val_loss: 45.5110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f969ba8aa00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Reconstruction: 90.67%\n"
     ]
    }
   ],
   "source": [
    "from verification_net import VerificationNet\n",
    "\n",
    "net = VerificationNet(force_learn=False, file_name=\"../models/verification_model\")\n",
    "img, labels = generator.get_random_batch(training=False, batch_size=25000)\n",
    "decoded_imgs = vae.predict(img)\n",
    "_, acc_ae = net.check_predictability(data=decoded_imgs, correct_labels=labels)\n",
    "_, acc_orig = net.check_predictability(data=img, correct_labels=labels)\n",
    "print(f\"Accuracy of Reconstruction: {100 * acc_ae:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "decoded_imgs = vae(x_test).mode().numpy()\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"model_14\" is incompatible with the layer: expected shape=(None, 16), found shape=(1, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_4163/2809875659.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\u001b[0m\u001b[1;32m    265\u001b[0m                              \u001b[0;34m'incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                              \u001b[0;34mf'expected shape={spec.shape}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"model_14\" is incompatible with the layer: expected shape=(None, 16), found shape=(1, 8)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "z = np.random.standard_normal((1, 8))\n",
    "decoder = keras.Model(decoder_input, decoded)\n",
    "x = decoder(z).mean()\n",
    "x = np.array(x).reshape((28,28))\n",
    "x[x >= 0.5] = 1.0\n",
    "x[x < 0.5] = 0.0\n",
    "\n",
    "plt.imshow(x)\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAABwCAYAAACkaY2RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAADiElEQVR4nO3dQWrDMBBAUankCl33/sfKPndQD9DQEnDjb/He2gjBMJuPjedaawAAAADQ8nH2BQAAAAD4SbQBAAAACBJtAAAAAIJEGwAAAIAg0QYAAAAgSLQBAAAACLq98vCc0//BT7LWmkecY4aneqy1Po84yBzPYxe3YBc3YBe3YBc3YBe3YBc3YBe38HQXvWkD73M/+wLAGMMuQoVdhAa7CA1Pd1G0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIEi0AQAAAAgSbQAAAACCRBsAAACAINEGAAAAIOj24vOPMcb9Py7Cr74OPMsMz2OO12eGezDH6zPDPZjj9ZnhHszx+sxwD0/nONda774IAAAAAH/weRQAAABAkGgDAAAAECTaAAAAAASJNgAAAABBog0AAABAkGgDAAAAECTaAAAAAASJNgAAAABBog0AAABA0DeT5kt68dYzGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "z = np.random.standard_normal((100, 16))\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoded)\n",
    "decoded_z = decoder(z).mode().numpy()\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(decoded_z[i-1].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ff9a1d55cbad36b515c3ded8837e12145fab330794be4b4ac6e95d3772d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

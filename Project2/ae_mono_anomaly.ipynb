{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               295040    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               2688      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              202272    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 558,645\n",
      "Trainable params: 558,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 19:05:28.201180: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            )(input_img)\n",
    "x = layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            )(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "encoded = layers.Dense(20)(x)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.InputLayer(input_shape=20)(encoded)\n",
    "x = layers.Dense(128, activation=\"relu\")(decoder_input)\n",
    "x = layers.Dense(7*7*32, activation=\"relu\")(x)\n",
    "x = layers.Reshape((7, 7, 32))(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "decoded = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.save_weights('initial_model.h5')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_2302/1236489056.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_2302/1236489056.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)\n"
     ]
    }
   ],
   "source": [
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "import numpy as np\n",
    "\n",
    "generator = StackedMNISTData(mode=DataMode.MONO_BINARY_MISSING, default_batch_size=2048)\n",
    "\n",
    "x_train, y_train = generator.get_full_data_set(training=True)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
    "x_test = x_test[:, :, :, [0]]\n",
    "y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "424/424 [==============================] - 30s 68ms/step - loss: 0.1817 - val_loss: 0.1047\n",
      "Epoch 2/10\n",
      "424/424 [==============================] - 28s 67ms/step - loss: 0.0765 - val_loss: 0.0750\n",
      "Epoch 3/10\n",
      "424/424 [==============================] - 31s 72ms/step - loss: 0.0621 - val_loss: 0.0659\n",
      "Epoch 4/10\n",
      "424/424 [==============================] - 31s 73ms/step - loss: 0.0562 - val_loss: 0.0608\n",
      "Epoch 5/10\n",
      "424/424 [==============================] - 31s 74ms/step - loss: 0.0526 - val_loss: 0.0627\n",
      "Epoch 6/10\n",
      "424/424 [==============================] - 29s 67ms/step - loss: 0.0504 - val_loss: 0.0588\n",
      "Epoch 7/10\n",
      "424/424 [==============================] - 28s 67ms/step - loss: 0.0485 - val_loss: 0.0582\n",
      "Epoch 8/10\n",
      "424/424 [==============================] - 28s 65ms/step - loss: 0.0472 - val_loss: 0.0578\n",
      "Epoch 9/10\n",
      "424/424 [==============================] - 30s 71ms/step - loss: 0.0461 - val_loss: 0.0537\n",
      "Epoch 10/10\n",
      "424/424 [==============================] - 29s 69ms/step - loss: 0.0451 - val_loss: 0.0542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8b43b3c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_full = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=2048)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "x_test = x_test[:, :, :, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = autoencoder(x_test)\n",
    "bce = keras.losses.BinaryCrossentropy()\n",
    "losses = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    losses.append(bce(x_test[i], reconstructed[i]).numpy())\n",
    "losses = np.array(losses)\n",
    "ind = np.argpartition(losses, -10)[-10:] # Get the indices of the 10 largest losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_16360/1623119759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Display original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[ind[i-1]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ff9a1d55cbad36b515c3ded8837e12145fab330794be4b4ac6e95d3772d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_z = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:56:49.330664: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " z_params (Dense)            (None, 16)                36880     \n",
      "                                                                 \n",
      " z_layer (IndependentNormal)  ((None, 8),              0         \n",
      "                              (None, 8))                         \n",
      "                                                                 \n",
      " input_2 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1568)              14112     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " x_params (Flatten)          (None, 784)               0         \n",
      "                                                                 \n",
      " x_layer (IndependentBernoul  ((None, 28, 28, 1),      0         \n",
      " li)                          (None, 28, 28, 1))                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,057\n",
      "Trainable params: 107,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:56:49.536320: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "prior = tfp.distributions.Independent(\n",
    "            tfp.distributions.Normal(loc=tf.zeros(dim_z), scale=1.0),\n",
    "            reinterpreted_batch_ndims=1,\n",
    "        )\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            ) (input_img)\n",
    "x = layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            ) (x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(\n",
    "                tfp.layers.IndependentNormal.params_size(dim_z),\n",
    "                activation=None,\n",
    "                name=\"z_params\",\n",
    "            )(x)\n",
    "encoded = tfp.layers.IndependentNormal(\n",
    "                dim_z,\n",
    "                activity_regularizer=tfp.layers.KLDivergenceRegularizer(\n",
    "                    prior, weight=2.0\n",
    "                ),\n",
    "                name=\"z_layer\",)(x)\n",
    "\n",
    "decoder_input = layers.InputLayer(input_shape=dim_z)(encoded)\n",
    "x = layers.Dense(7 * 7 * 32, activation=None)(decoder_input)\n",
    "x = layers.Reshape((7, 7, 32))(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "x = layers.Flatten(name=\"x_params\")(x)\n",
    "decoded = tfp.layers.IndependentBernoulli((28, 28, 1), name=\"x_layer\")(x)\n",
    "vae = keras.Model(input_img, decoded)\n",
    "vae.compile(optimizer='adam', loss=lambda x, y: -y.log_prob(x))\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_17178/1236489056.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_17178/1236489056.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)\n"
     ]
    }
   ],
   "source": [
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "import numpy as np\n",
    "\n",
    "generator = StackedMNISTData(mode=DataMode.MONO_BINARY_MISSING, default_batch_size=2048)\n",
    "\n",
    "x_train, y_train = generator.get_full_data_set(training=True)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
    "x_test = x_test[:, :, :, [0]]\n",
    "y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "424/424 [==============================] - 26s 59ms/step - loss: 205.4533 - val_loss: 171.5074\n",
      "Epoch 2/10\n",
      "424/424 [==============================] - 26s 60ms/step - loss: 152.6982 - val_loss: 151.2722\n",
      "Epoch 3/10\n",
      "424/424 [==============================] - 25s 58ms/step - loss: 143.8776 - val_loss: 146.2056\n",
      "Epoch 4/10\n",
      "424/424 [==============================] - 28s 66ms/step - loss: 140.6587 - val_loss: 144.3297\n",
      "Epoch 5/10\n",
      "424/424 [==============================] - 28s 66ms/step - loss: 138.4539 - val_loss: 144.0818\n",
      "Epoch 6/10\n",
      "424/424 [==============================] - 27s 64ms/step - loss: 136.9515 - val_loss: 141.7054\n",
      "Epoch 7/10\n",
      "424/424 [==============================] - 27s 65ms/step - loss: 135.8286 - val_loss: 140.9304\n",
      "Epoch 8/10\n",
      "424/424 [==============================] - 28s 65ms/step - loss: 134.9621 - val_loss: 140.2076\n",
      "Epoch 9/10\n",
      "424/424 [==============================] - 27s 64ms/step - loss: 134.4118 - val_loss: 139.9753\n",
      "Epoch 10/10\n",
      "424/424 [==============================] - 27s 65ms/step - loss: 133.8287 - val_loss: 139.7309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed19987f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_full = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=2048)\n",
    "x_test, y_test = generator.get_random_batch(training=False, batch_size=2000)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "x_test = x_test[:, :, :, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = vae(x_test).mode()\n",
    "bce = keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "losses = bce(x_test, reconstructed).numpy()\n",
    "sum_losses = np.sum(losses, axis=(1, 2))\n",
    "ind = np.argpartition(sum_losses, -10)[-10:] # Get the indices of the 10 largest losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[ind[i-1]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "z = np.random.randn(N, 8)\n",
    "decoder = keras.Model(decoder_input, decoded)\n",
    "decoded_z = decoder(z).mode()\n",
    "bce = keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    x = x_test[i]\n",
    "    x = np.repeat(x[np.newaxis, :, :, :], N, axis=0)\n",
    "    loss = bce(x, decoded_z).numpy()\n",
    "    loss = np.average(loss, axis=(1, 2))\n",
    "    loss = np.exp(loss)\n",
    "    loss = np.sum(loss)/N\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.argpartition(losses, -10)[-10:] # Get the indices of the 10 largest losses\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[ind[i-1]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ff9a1d55cbad36b515c3ded8837e12145fab330794be4b4ac6e95d3772d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

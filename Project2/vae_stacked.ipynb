{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_z = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 15:44:11.676794: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " z_params (Dense)            (None, 16)                36880     \n",
      "                                                                 \n",
      " z_layer (IndependentNormal)  ((None, 8),              0         \n",
      "                              (None, 8))                         \n",
      "                                                                 \n",
      " input_2 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1568)              14112     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " x_params (Flatten)          (None, 784)               0         \n",
      "                                                                 \n",
      " x_layer (IndependentBernoul  ((None, 28, 28, 1),      0         \n",
      " li)                          (None, 28, 28, 1))                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,057\n",
      "Trainable params: 107,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 15:44:11.908012: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "prior = tfp.distributions.Independent(\n",
    "            tfp.distributions.Normal(loc=tf.zeros(dim_z), scale=1.0),\n",
    "            reinterpreted_batch_ndims=1,\n",
    "        )\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            ) (input_img)\n",
    "x = layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            ) (x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(\n",
    "                tfp.layers.IndependentNormal.params_size(dim_z),\n",
    "                activation=None,\n",
    "                name=\"z_params\",\n",
    "            )(x)\n",
    "encoded = tfp.layers.IndependentNormal(\n",
    "                dim_z,\n",
    "                activity_regularizer=tfp.layers.KLDivergenceRegularizer(\n",
    "                    prior, weight=2.0\n",
    "                ),\n",
    "                name=\"z_layer\",)(x)\n",
    "\n",
    "decoder_input = layers.InputLayer(input_shape=dim_z)(encoded)\n",
    "x = layers.Dense(7 * 7 * 32, activation=None)(decoder_input)\n",
    "x = layers.Reshape((7, 7, 32))(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "x = layers.Flatten(name=\"x_params\")(x)\n",
    "decoded = tfp.layers.IndependentBernoulli((28, 28, 1), name=\"x_layer\")(x)\n",
    "vae = keras.Model(input_img, decoded)\n",
    "vae.compile(optimizer='adam', loss=lambda x, y: -y.log_prob(x))\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_17597/4188248072.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_17597/4188248072.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)\n"
     ]
    }
   ],
   "source": [
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "import numpy as np\n",
    "\n",
    "generator = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=2048)\n",
    "\n",
    "x_train, y_train = generator.get_full_data_set(training=True)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
    "x_test = x_test[:, :, :, [0]]\n",
    "y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 32s 65ms/step - loss: 199.0708 - val_loss: 155.7756\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 31s 65ms/step - loss: 151.1450 - val_loss: 146.8572\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 146.0278 - val_loss: 143.2922\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 143.2144 - val_loss: 141.1682\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 141.4784 - val_loss: 140.4079\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 31s 65ms/step - loss: 140.2909 - val_loss: 139.2278\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 139.4282 - val_loss: 138.1811\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 138.5748 - val_loss: 137.7445\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 138.0453 - val_loss: 137.1992\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 31s 67ms/step - loss: 137.5901 - val_loss: 137.0925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f922904fe50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = StackedMNISTData(mode=DataMode.COLOR_BINARY_COMPLETE, default_batch_size=2048)\n",
    "x_test, y_test = generator.get_random_batch(training=False, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = np.zeros(x_test.shape)\n",
    "for i in range(3):\n",
    "    reconstructed[:,:,:,[i]] = vae(x_test[:,:,:,[i]]).mode()\n",
    "x_test = x_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Reconstruction: 55.70%\n",
      "Accuracy of Original: 86.85%\n"
     ]
    }
   ],
   "source": [
    "from verification_net import VerificationNet\n",
    "\n",
    "net = VerificationNet(force_learn=False, file_name=\"../models/verification_model\")\n",
    "_, acc_orig = net.check_predictability(data=x_test, correct_labels=y_test)\n",
    "_, acc_ae = net.check_predictability(data=reconstructed, correct_labels=y_test)\n",
    "\n",
    "print(f\"Accuracy of Reconstruction: {100 * acc_ae:.2f}%\")\n",
    "print(f\"Accuracy of Original: {100 * acc_orig:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(reconstructed[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nr_examples = 2000 \n",
    "generated = np.zeros((nr_examples, 28, 28, 3))\n",
    "decoder = keras.Model(decoder_input, decoded)\n",
    "\n",
    "for i in range(3):\n",
    "    z = np.random.randn(nr_examples, 8)\n",
    "    generated[:,:,:,[i]] = decoder(z).mode()\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(generated[i-1])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 27.50%\n",
      "Predictability: 44.90%\n"
     ]
    }
   ],
   "source": [
    "cov = net.check_class_coverage(data=generated, tolerance=0.98)\n",
    "pred, _ = net.check_predictability(data=generated)\n",
    "print(f\"Coverage: {100*cov:.2f}%\")\n",
    "print(f\"Predictability: {100*pred:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ff9a1d55cbad36b515c3ded8837e12145fab330794be4b4ac6e95d3772d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               295040    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               2688      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              202272    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 558,645\n",
      "Trainable params: 558,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 19:05:28.201180: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            )(input_img)\n",
    "x = layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                strides=(2, 2),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "            )(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Dense(20)(encoded)\n",
    "x = layers.Dense(128, activation=\"relu\")(decoder_input)\n",
    "x = layers.Dense(7*7*32, activation=\"relu\")(x)\n",
    "x = layers.Reshape((7, 7, 32))(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"\n",
    "            )(x)\n",
    "decoded = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_2302/1236489056.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
      "/var/folders/w2/4g3c4yrn38g2nwwdhjdlx6fc0000gn/T/ipykernel_2302/1236489056.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)\n"
     ]
    }
   ],
   "source": [
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "import numpy as np\n",
    "\n",
    "generator = StackedMNISTData(mode=DataMode.MONO_BINARY_MISSING, default_batch_size=2048)\n",
    "\n",
    "x_train, y_train = generator.get_full_data_set(training=True)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "y_train = keras.utils.to_categorical((y_train % 10).astype(np.int), 10)\n",
    "x_test = x_test[:, :, :, [0]]\n",
    "y_test = keras.utils.to_categorical((y_test % 10).astype(np.int), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "424/424 [==============================] - 30s 68ms/step - loss: 0.1817 - val_loss: 0.1047\n",
      "Epoch 2/10\n",
      "424/424 [==============================] - 28s 67ms/step - loss: 0.0765 - val_loss: 0.0750\n",
      "Epoch 3/10\n",
      "424/424 [==============================] - 31s 72ms/step - loss: 0.0621 - val_loss: 0.0659\n",
      "Epoch 4/10\n",
      "424/424 [==============================] - 31s 73ms/step - loss: 0.0562 - val_loss: 0.0608\n",
      "Epoch 5/10\n",
      "424/424 [==============================] - 31s 74ms/step - loss: 0.0526 - val_loss: 0.0627\n",
      "Epoch 6/10\n",
      "424/424 [==============================] - 29s 67ms/step - loss: 0.0504 - val_loss: 0.0588\n",
      "Epoch 7/10\n",
      "424/424 [==============================] - 28s 67ms/step - loss: 0.0485 - val_loss: 0.0582\n",
      "Epoch 8/10\n",
      "424/424 [==============================] - 28s 65ms/step - loss: 0.0472 - val_loss: 0.0578\n",
      "Epoch 9/10\n",
      "424/424 [==============================] - 30s 71ms/step - loss: 0.0461 - val_loss: 0.0537\n",
      "Epoch 10/10\n",
      "424/424 [==============================] - 29s 69ms/step - loss: 0.0451 - val_loss: 0.0542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8b43b3c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_full = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=2048)\n",
    "x_test, y_test = generator.get_full_data_set(training=False)\n",
    "\n",
    "# \"Translate\": Only look at \"red\" channel; only use the last digit. Use one-hot for labels during training\n",
    "x_train = x_train[:, :, :, [0]]\n",
    "x_test = x_test[:, :, :, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = autoencoder(x_test)\n",
    "bce = keras.losses.BinaryCrossentropy()\n",
    "losses = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    losses.append(bce(x_test[i], reconstructed[i]).numpy())\n",
    "losses = np.array(losses)\n",
    "ind = np.argpartition(losses, -10)[-10:] # Get the indices of the 10 largest losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[ind[i-1]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ff9a1d55cbad36b515c3ded8837e12145fab330794be4b4ac6e95d3772d975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
